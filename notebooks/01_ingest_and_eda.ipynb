{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd9e68a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "No CSVs found matching Inclusive_Growth_Score_Data_Export_*_BaltimoreCity_CensusTractLevel.csv in /Users/warrenjones/Dev/igs-analysis-baltimore/notebooks",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m PATTERN = \u001b[33m\"\u001b[39m\u001b[33mInclusive_Growth_Score_Data_Export_*_BaltimoreCity_CensusTractLevel.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     19\u001b[39m csvs = \u001b[38;5;28msorted\u001b[39m(RAW.glob(PATTERN))\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m csvs, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo CSVs found matching \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPATTERN\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRAW\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFound CSVs:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m csvs: \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m •\u001b[39m\u001b[33m\"\u001b[39m, p.relative_to(ROOT))\n",
      "\u001b[31mAssertionError\u001b[39m: No CSVs found matching Inclusive_Growth_Score_Data_Export_*_BaltimoreCity_CensusTractLevel.csv in /Users/warrenjones/Dev/igs-analysis-baltimore/notebooks"
     ]
    }
   ],
   "source": [
    "# --- IGS Baltimore: ingest + quick EDA ---------------------------------------\n",
    "# Works whether your CSVs are in repo root or in data_raw/.\n",
    "# Produces: data/clean/igs_baltimore.parquet and basic summary prints.\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- Paths\n",
    "ROOT = Path(__file__).resolve().parents[1] if \"__file__\" in globals() else Path.cwd()\n",
    "RAW = (ROOT / \"data_raw\") if (ROOT / \"data_raw\").exists() else ROOT\n",
    "OUT = ROOT / \"data\" / \"clean\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Find IGS CSVs\n",
    "PATTERN = \"Inclusive_Growth_Score_Data_Export_*_BaltimoreCity_CensusTractLevel.csv\"\n",
    "csvs = sorted(RAW.glob(PATTERN))\n",
    "assert csvs, f\"No CSVs found matching {PATTERN} in {RAW}\"\n",
    "\n",
    "print(\"Found CSVs:\")\n",
    "for p in csvs: print(\" •\", p.relative_to(ROOT))\n",
    "\n",
    "# ---------- Helpers\n",
    "def to_snake(name: str) -> str:\n",
    "    name = re.sub(r\"[^\\w]+\", \"_\", name.strip())\n",
    "    name = re.sub(r\"__+\", \"_\", name).strip(\"_\")\n",
    "    return name.lower()\n",
    "\n",
    "def extract_year_from_df_or_name(df: pd.DataFrame, path: Path) -> int | None:\n",
    "    # Common IGS year columns—adjust if needed\n",
    "    for col in df.columns:\n",
    "        if col.lower() in {\"year\",\"fy\",\"report_year\",\"reporting_year\"}:\n",
    "            try: return int(pd.to_numeric(df[col]).iloc[0])\n",
    "            except Exception: pass\n",
    "    # Fallback: look for a 4-digit year in filename\n",
    "    m = re.search(r\"(20\\d{2})\", path.name)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "# ---------- Load + normalize\n",
    "frames = []\n",
    "for p in csvs:\n",
    "    df = pd.read_csv(p, dtype=str)  # keep IDs exact\n",
    "    # Standardize columns\n",
    "    df.columns = [to_snake(c) for c in df.columns]\n",
    "\n",
    "    # Try to create a consistent census tract key and year\n",
    "    # Adjust these mappings to match your file’s actual column names\n",
    "    # (print(df.columns) on first run if unsure)\n",
    "    col_map = {\n",
    "        \"geoid\": [\"geoid\", \"census_tract_geoid\", \"tract_geoid\", \"census_tract\"],\n",
    "        \"tract_name\": [\"name\", \"tract_name\"],\n",
    "        \"county\": [\"county\", \"county_name\"],\n",
    "        \"state\": [\"state\", \"state_name\"],\n",
    "        \"city\": [\"city\", \"city_name\", \"municipality\"],\n",
    "        \"igs_score\": [\"inclusive_growth_score\", \"igs_score\", \"score\"],\n",
    "    }\n",
    "\n",
    "    norm = {}\n",
    "    for std, candidates in col_map.items():\n",
    "        for c in candidates:\n",
    "            if c in df.columns:\n",
    "                norm[std] = df[c]\n",
    "                break\n",
    "\n",
    "    # Attach normalized columns (only where found)\n",
    "    for k, v in norm.items():\n",
    "        df[k] = v\n",
    "\n",
    "    # Strip whitespace, keep geoid as string\n",
    "    if \"geoid\" in df:\n",
    "        df[\"geoid\"] = df[\"geoid\"].str.strip()\n",
    "\n",
    "    # --- Numeric coercion (safe + Pylance friendly)\n",
    "cols = [str(c) for c in df.columns]\n",
    "num_candidates = [c for c in cols if any(sub in c for sub in (\"score\", \"index\", \"rate\", \"pct\", \"share\"))]\n",
    "\n",
    "for c in num_candidates:\n",
    "    # force string, drop thousands commas, then coerce to numeric\n",
    "    s = df[c].astype(str).str.replace(\",\", \"\", regex=False)\n",
    "    df[c] = pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "\n",
    "    # Year\n",
    "    yr = extract_year_from_df_or_name(df, p)\n",
    "    if yr: df[\"year\"] = yr\n",
    "\n",
    "    # Source filename for traceability\n",
    "    df[\"source_file\"] = p.name\n",
    "    frames.append(df)\n",
    "\n",
    "raw = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# ---------- Minimal cleaning\n",
    "# Deduplicate exact rows\n",
    "raw = raw.drop_duplicates()\n",
    "\n",
    "# If both city and tracts exist, keep tract granularity (drop citywide rows)\n",
    "if \"geoid\" in raw and raw[\"geoid\"].notna().any():\n",
    "    # heuristics: GEOIDs are 11 or more digits for tracts; filter out null/short\n",
    "    raw = raw[raw[\"geoid\"].str.len().fillna(0) >= 11]\n",
    "\n",
    "# ---------- Save clean parquet\n",
    "clean_path = OUT / \"igs_baltimore.parquet\"\n",
    "raw.to_parquet(clean_path, index=False)\n",
    "print(f\"\\nSaved clean file → {clean_path.relative_to(ROOT)}  ({len(raw):,} rows)\")\n",
    "\n",
    "# ---------- Quick EDA\n",
    "print(\"\\n=== Columns ===\")\n",
    "print(sorted(raw.columns))\n",
    "\n",
    "print(\"\\n=== Missing values (top 20) ===\")\n",
    "print(raw.isna().sum().sort_values(ascending=False).head(20))\n",
    "\n",
    "num_cols = [c for c in raw.columns if pd.api.types.is_numeric_dtype(raw[c])]\n",
    "print(\"\\n=== Numeric summary (head) ===\")\n",
    "print(raw[num_cols].describe().T.head(10))\n",
    "\n",
    "# Top/bottom tracts by IGS (if available)\n",
    "score_col = next((c for c in [\"igs_score\",\"inclusive_growth_score\"] if c in raw.columns), None)\n",
    "if score_col:\n",
    "    print(\"\\n=== Top 10 tracts by IGS ===\")\n",
    "    print(raw[[\"geoid\", \"tract_name\", score_col, \"year\"]]\n",
    "          .sort_values(score_col, ascending=False).head(10))\n",
    "\n",
    "    print(\"\\n=== Bottom 10 tracts by IGS ===\")\n",
    "    print(raw[[\"geoid\", \"tract_name\", score_col, \"year\"]]\n",
    "          .sort_values(score_col, ascending=True).head(10))\n",
    "\n",
    "    # Simple histogram\n",
    "    plt.figure(figsize=(6,4))\n",
    "    raw[score_col].dropna().plot(kind=\"hist\", bins=30, edgecolor=\"black\")\n",
    "    plt.title(\"Distribution of IGS (tract level)\")\n",
    "    plt.xlabel(score_col)\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Trend over time (if year present)\n",
    "if \"year\" in raw.columns and score_col:\n",
    "    trend = (raw.groupby(\"year\")[score_col]\n",
    "             .mean().reset_index().sort_values(\"year\"))\n",
    "    print(\"\\n=== Citywide mean IGS by year ===\")\n",
    "    print(trend)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(trend[\"year\"], trend[score_col], marker=\"o\")\n",
    "    plt.title(\"Citywide Mean IGS by Year\")\n",
    "    plt.xlabel(\"year\")\n",
    "    plt.ylabel(score_col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
